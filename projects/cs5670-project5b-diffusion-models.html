<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>CS5670 Project 5B: Training Diffusion Models from Scratch</title>
    <link rel="stylesheet" type="text/css" href="../style.css">
    <style>
        body {
            margin: 0;
            padding: 0;
            font-family: 'Source Sans Pro', Helvetica, sans-serif;
            background: #fff;
            color: #333;
        }
        
        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 40px 20px;
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
        }
        
        .header h1 {
            font-size: 2.5em;
            font-weight: 300;
            margin: 0 0 10px 0;
            color: #2c3e50;
        }
        
        .header .subtitle {
            font-size: 1.2em;
            color: #7f8c8d;
            margin-bottom: 20px;
        }
        
        .nav-back {
            text-align: left;
            margin-bottom: 30px;
        }
        
        .nav-back a {
            color: #3498db;
            text-decoration: none;
            font-size: 0.9em;
        }
        
        .nav-back a:hover {
            text-decoration: underline;
        }
        
        .project-overview {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
        }
        
        .demo-image {
            text-align: center;
            margin: 30px 0;
        }
        
        .demo-image img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        .demo-image .caption {
            font-style: italic;
            color: #7f8c8d;
            margin-top: 10px;
            font-size: 0.9em;
        }
        
        h2 {
            color: #2c3e50;
            font-weight: 400;
            border-bottom: 2px solid #ecf0f1;
            padding-bottom: 10px;
            margin-top: 40px;
        }
        
        h3 {
            color: #34495e;
            font-weight: 400;
            margin-top: 30px;
        }
        
        .key-info {
            background: #e8f4fd;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        
        .key-info h3 {
            margin-top: 0;
            color: #2980b9;
        }
        
        .key-info table {
            width: 100%;
            border-collapse: collapse;
        }
        
        .key-info td {
            padding: 8px 0;
            vertical-align: top;
        }
        
        .key-info td:first-child {
            font-weight: 600;
            width: 150px;
        }
        
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 30px 0;
        }
        
        .result-item {
            text-align: center;
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
        }
        
        .result-item img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            margin-bottom: 10px;
        }
        
        .result-item .label {
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 5px;
            font-size: 0.9em;
        }
        
        .result-item .description {
            font-size: 0.8em;
            color: #7f8c8d;
        }
        
        .implementation-section {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            margin: 30px 0;
        }
        
        .math-section {
            background: #fff;
            padding: 20px;
            border-radius: 6px;
            border-left: 4px solid #9b59b6;
            margin: 20px 0;
        }
        
        .algorithm-steps {
            background: #fff;
            padding: 20px;
            border-radius: 6px;
            border-left: 4px solid #e74c3c;
        }
        
        .algorithm-steps ol {
            margin: 0;
            padding-left: 20px;
        }
        
        .algorithm-steps li {
            margin: 12px 0;
            line-height: 1.6;
        }
        
        .unet-architecture {
            background: #fff;
            padding: 20px;
            border-radius: 6px;
            border-left: 4px solid #2ecc71;
            margin: 20px 0;
        }
        
        .my-results {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
        }
        
        .my-results h3 {
            color: #856404;
            margin-top: 0;
        }
        
        .mnist-section {
            background: #fef7f0;
            border: 1px solid #f4d5a7;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 4px solid #e67e22;
        }
        
        .mnist-section h3 {
            color: #d35400;
            margin-top: 0;
        }
        
        .training-progression {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .epoch-item {
            text-align: center;
            background: #fff;
            padding: 15px;
            border-radius: 6px;
            border: 2px solid #ecf0f1;
        }
        
        .epoch-item h4 {
            margin: 0 0 10px 0;
            color: #2c3e50;
            font-size: 0.9em;
        }
        
        .epoch-item.final {
            border-color: #27ae60;
        }
        
        .noise-levels {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 10px;
            margin: 20px 0;
        }
        
        .noise-item {
            text-align: center;
            background: #fff;
            padding: 10px;
            border-radius: 6px;
            border: 1px solid #ecf0f1;
        }
        
        .noise-item .sigma-label {
            font-weight: bold;
            color: #e74c3c;
            font-size: 0.8em;
        }
        
        .time-conditioning-section {
            background: #f0f9ff;
            border: 1px solid #bfdbfe;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 4px solid #3b82f6;
        }
        
        .time-conditioning-section h3 {
            color: #1e40af;
            margin-top: 0;
        }
        
        .class-conditioning-section {
            background: #f0fdf4;
            border: 1px solid #bbf7d0;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 4px solid #16a34a;
        }
        
        .class-conditioning-section h3 {
            color: #15803d;
            margin-top: 0;
        }
        
        .loss-curves {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .loss-curve-item {
            background: #fff;
            padding: 15px;
            border-radius: 6px;
            text-align: center;
        }
        
        .architecture-diagram {
            background: #fff;
            padding: 20px;
            border-radius: 6px;
            text-align: center;
            margin: 20px 0;
            border: 2px solid #ecf0f1;
        }
        
        .architecture-diagram img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
        }
        
        .architecture-diagram .diagram-title {
            font-weight: bold;
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.1em;
        }
        
        .ddpm-training {
            background: #fff5f5;
            border: 1px solid #fed7d7;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 4px solid #e53e3e;
        }
        
        .ddpm-training h3 {
            color: #c53030;
            margin-top: 0;
        }
        
        .cfg-sampling {
            background: #f0f9ff;
            border: 1px solid #bfdbfe;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 4px solid #3b82f6;
        }
        
        .cfg-sampling h3 {
            color: #1e40af;
            margin-top: 0;
        }
        
        .generated-digits {
            display: grid;
            grid-template-columns: repeat(10, 1fr);
            gap: 5px;
            margin: 15px 0;
            padding: 10px;
            background: #fff;
            border-radius: 6px;
        }
        
        .digit-item {
            text-align: center;
            padding: 5px;
            border-radius: 4px;
            background: #f8f9fa;
        }
        
        .digit-item img {
            width: 100%;
            border-radius: 2px;
        }
        
        .digit-item .digit-label {
            font-size: 0.7em;
            color: #666;
            margin-top: 2px;
        }
        
        .extra-credit-section {
            background: #fff9e6;
            border: 1px solid #ffe066;
            padding: 20px;
            border-radius: 8px;
            margin: 30px 0;
            border-left: 4px solid #ffd700;
        }
        
        .extra-credit-section h3 {
            color: #b8860b;
            margin-top: 0;
        }
        
        .variance-schedule {
            background: #fff;
            padding: 15px;
            border-radius: 6px;
            border: 1px solid #d1ecf1;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        .variance-schedule h4 {
            margin: 0 0 10px 0;
            font-family: 'Source Sans Pro', sans-serif;
            color: #0c5460;
        }
        
        .fcblock-diagram {
            background: #fff;
            padding: 15px;
            border-radius: 6px;
            border: 2px solid #3b82f6;
            margin: 15px 0;
            text-align: center;
        }
        
        .code-snippet {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 6px;
            border-left: 4px solid #6c757d;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.4;
        }
        
        .denoising-comparison {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .denoise-method {
            background: #fff;
            padding: 15px;
            border-radius: 6px;
            text-align: center;
            border: 2px solid #ecf0f1;
        }
        
        .denoise-method.one-step {
            border-color: #f39c12;
        }
        
        .denoise-method.diffusion {
            border-color: #27ae60;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="nav-back">
            <a href="../index.html">← Back to Projects</a>
        </div>
        
        <div class="header">
            <h1>Training Diffusion Models from Scratch</h1>
            <div class="subtitle">CS5670 Project 5B - Introduction to Computer Vision</div>
            <div class="subtitle">Cornell University, Spring 2025</div>
        </div>
        
        <div class="project-overview">
            <p><strong>Train your own diffusion model on the MNIST dataset from the ground up.</strong></p>
            <p>This project provides deep insights into diffusion model training by implementing UNet architectures, understanding DDPM mathematics, and progressing from simple one-step denoisers to full conditional diffusion models with classifier-free guidance.</p>
        </div>
        
        <div class="demo-image">
            <img src="../images/diffusion-b-mnist-progression.png" alt="MNIST Diffusion Model Training Progression" style="max-width: 100%; height: auto; border-radius: 4px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            <div class="caption">Training progression: From noisy samples to clean MNIST digit generation over 20 epochs</div>
        </div>
        
        <div class="key-info">
            <h3>Project Details</h3>
            <table>
                <tr>
                    <td>Assigned:</td>
                    <td>Thursday, April 17, 2025</td>
                </tr>
                <tr>
                    <td>Due:</td>
                    <td>Tuesday, May 6, 2025 (Part B)</td>
                </tr>
                <tr>
                    <td>Individual Work:</td>
                    <td>Must be completed individually</td>
                </tr>
                <tr>
                    <td>Platform:</td>
                    <td>Google Colab with GPU acceleration</td>
                </tr>
                <tr>
                    <td>Key Concepts:</td>
                    <td>UNet architecture, DDPM training, time conditioning, CFG</td>
                </tr>
            </table>
        </div>
        
        <h2>Overview</h2>
        <p>Training diffusion models from scratch provides invaluable insights into how these powerful generative models learn to transform noise into meaningful data. This project takes us through the complete journey from implementing UNet architectures to training state-of-the-art conditional diffusion models.</p>
        
        <p>Working with the MNIST dataset allows us to focus on the core algorithms while maintaining reasonable training times. We progress from simple one-step denoisers to full DDPM implementation with time and class conditioning.</p>
        
        <h2>Part 1: Single-Step Denoising UNet</h2>
        
        <h3>1.1 UNet Architecture Implementation</h3>
        <div class="implementation-section">
            <p>The UNet serves as the backbone of our diffusion model, featuring downsampling and upsampling paths with skip connections for multi-scale feature processing.</p>
            
            <div class="architecture-diagram">
                <div class="diagram-title">Unconditional UNet Architecture</div>
                <img src="../images/diffusion-b-unet-architecture.png" alt="UNet Architecture Diagram" style="max-width: 100%; height: auto; border-radius: 4px;">
            </div>
            
            <div class="unet-architecture">
                <h4>Core UNet Components:</h4>
                <div class="algorithm-steps">
                    <ol>
                        <li><strong>Conv:</strong> Convolutional layer preserving spatial dimensions</li>
                        <li><strong>DownConv:</strong> Downsampling convolution (stride=2)</li>
                        <li><strong>UpConv:</strong> Upsampling transposed convolution (stride=2)</li>
                        <li><strong>Flatten:</strong> Average pooling to reduce 7×7 → 1×1</li>
                        <li><strong>Unflatten:</strong> Expand 1×1 → 7×7 through convolution</li>
                        <li><strong>Skip Connections:</strong> Concatenate features across scales</li>
                    </ol>
                </div>
                
                <div class="architecture-diagram">
                    <div class="diagram-title">UNet Operations Detail</div>
                    <img src="../images/diffusion-b-unet-operations.png" alt="UNet Operations Diagram" style="max-width: 100%; height: auto; border-radius: 4px;">
                </div>
            </div>
        </div>
        
        <h3>1.2 Single-Step Denoiser Training</h3>
        <div class="implementation-section">
            <p>We begin with the fundamental denoising task: given a noisy image, predict the clean version in a single step.</p>
            
            <div class="math-section">
                <h4>Single-Step Denoising Objective:</h4>
                <img src="../images/diffusion-b-single-step-loss.png" alt="Single-Step Denoising Loss Function" style="max-width: 100%; height: auto; border-radius: 4px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                
                <h4>Noise Generation Process:</h4>
                <img src="../images/diffusion-b-noise-generation.png" alt="Noise Generation Mathematics" style="max-width: 100%; height: auto; border-radius: 4px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </div>
            
            <div class="mnist-section">
                <h3>MNIST Training Setup</h3>
                <div class="variance-schedule">
                    <h4>Training Configuration:</h4>
                    <strong>Dataset:</strong> MNIST (60,000 training images)<br>
                    <strong>Batch Size:</strong> 256<br>
                    <strong>Epochs:</strong> 5<br>
                    <strong>Optimizer:</strong> Adam (lr=1e-4)<br>
                    <strong>Hidden Dimension:</strong> D = 128<br>
                    <strong>Noise Level:</strong> σ = 0.5
                </div>
            </div>
        </div>
        
        <h3>Noise Level Visualization</h3>
        <div class="noise-levels">
            <div class="noise-item">
                <img src="../images/diffusion-b-mnist-sigma-0.png" alt="MNIST σ=0.0" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="sigma-label">σ = 0.0</div>
            </div>
            
            <div class="noise-item">
                <img src="../images/diffusion-b-mnist-sigma-0.2.png" alt="MNIST σ=0.2" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="sigma-label">σ = 0.2</div>
            </div>
            
            <div class="noise-item">
                <img src="../images/diffusion-b-mnist-sigma-0.4.png" alt="MNIST σ=0.4" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="sigma-label">σ = 0.4</div>
            </div>
            
            <div class="noise-item">
                <img src="../images/diffusion-b-mnist-sigma-0.6.png" alt="MNIST σ=0.6" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="sigma-label">σ = 0.6</div>
            </div>
            
            <div class="noise-item">
                <img src="../images/diffusion-b-mnist-sigma-0.8.png" alt="MNIST σ=0.8" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="sigma-label">σ = 0.8</div>
            </div>
            
            <div class="noise-item">
                <img src="../images/diffusion-b-mnist-sigma-1.0.png" alt="MNIST σ=1.0" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="sigma-label">σ = 1.0</div>
            </div>
        </div>
        
        <h3>Training Results</h3>
        <div class="loss-curves">
            <div class="loss-curve-item">
                <img src="../images/diffusion-b-single-step-loss-curve.png" alt="Single-Step Training Loss Curve" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="label">Training Loss Curve</div>
                <div class="description">5 epochs of single-step denoiser training</div>
            </div>
        </div>
        
        <div class="training-progression">
            <div class="epoch-item">
                <h4>Epoch 1</h4>
                <img src="../images/diffusion-b-single-step-epoch1.png" alt="Single-Step Results Epoch 1" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="description">Initial denoising capability</div>
            </div>
            
            <div class="epoch-item final">
                <h4>Epoch 5</h4>
                <img src="../images/diffusion-b-single-step-epoch5.png" alt="Single-Step Results Epoch 5" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="description">Converged denoising performance</div>
            </div>
        </div>
        
        <h3>Out-of-Distribution Testing</h3>
        <div class="implementation-section">
            <p>Testing the single-step denoiser on noise levels it wasn't trained on reveals the limitations of this approach and motivates iterative diffusion.</p>
            
            <div class="noise-levels">
                <div class="noise-item">
                    <img src="../images/diffusion-b-ood-sigma-0.1.png" alt="OOD σ=0.1" style="max-width: 100%; height: auto; border-radius: 4px;">
                    <div class="sigma-label">σ = 0.1</div>
                </div>
                
                <div class="noise-item">
                    <img src="../images/diffusion-b-ood-sigma-0.3.png" alt="OOD σ=0.3" style="max-width: 100%; height: auto; border-radius: 4px;">
                    <div class="sigma-label">σ = 0.3</div>
                </div>
                
                <div class="noise-item">
                    <img src="../images/diffusion-b-ood-sigma-0.7.png" alt="OOD σ=0.7" style="max-width: 100%; height: auto; border-radius: 4px;">
                    <div class="sigma-label">σ = 0.7</div>
                </div>
                
                <div class="noise-item">
                    <img src="../images/diffusion-b-ood-sigma-0.9.png" alt="OOD σ=0.9" style="max-width: 100%; height: auto; border-radius: 4px;">
                    <div class="sigma-label">σ = 0.9</div>
                </div>
            </div>
        </div>
        
        <h2>Part 2: Full DDPM Training</h2>
        
        <h3>2.1 Time-Conditioned UNet Architecture</h3>
        <div class="time-conditioning-section">
            <h3>Adding Temporal Conditioning</h3>
            <p>To enable iterative denoising, we condition the UNet on timestep t, allowing it to adapt its behavior based on the current noise level.</p>
            
            <div class="architecture-diagram">
                <div class="diagram-title">Time-Conditioned UNet</div>
                <img src="../images/diffusion-b-time-conditioned-unet.png" alt="Time-Conditioned UNet Architecture" style="max-width: 100%; height: auto; border-radius: 4px;">
            </div>
            
            <div class="fcblock-diagram">
                <div class="diagram-title">FCBlock for Time Embedding</div>
                <img src="../images/diffusion-b-fcblock-diagram.png" alt="FCBlock Architecture" style="max-width: 100%; height: auto; border-radius: 4px;">
            </div>
            
            <div class="code-snippet">
# Time conditioning implementation
fc1_t = FCBlock(1, hidden_dim)  # Scalar timestep input
fc2_t = FCBlock(1, hidden_dim)

# Normalize timestep to [0, 1]
t_normalized = t / 300.0

# Embed and inject conditioning
t1 = fc1_t(t_normalized)
t2 = fc2_t(t_normalized)

# Modulate UNet features
unflatten = unflatten + t1
up1 = up1 + t2
            </div>
        </div>
        
        <h3>2.2 DDPM Mathematics and Variance Schedule</h3>
        <div class="implementation-section">
            <p>DDPM requires careful design of the noise schedule that controls how noise is added during training and removed during sampling.</p>
            
            <div class="math-section">
                <h4>DDPM Training Objective:</h4>
                <img src="../images/diffusion-b-ddpm-loss.png" alt="DDPM Training Loss Function" style="max-width: 100%; height: auto; border-radius: 4px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                
                <h4>Forward Process with Schedule:</h4>
                <img src="../images/diffusion-b-forward-process-schedule.png" alt="DDPM Forward Process Mathematics" style="max-width: 100%; height: auto; border-radius: 4px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </div>
            
            <div class="variance-schedule">
                <h4>DDPM Variance Schedule (T=300):</h4>
                <strong>β schedule:</strong> Linear from 1e-4 to 0.02<br>
                <strong>α_t:</strong> 1 - β_t<br>
                <strong>ᾱ_t:</strong> Cumulative product of α values<br>
                <strong>Properties:</strong> ᾱ_0 ≈ 1 (clean), ᾱ_T ≈ 0 (pure noise)
            </div>
        </div>
        
        <h3>2.3 DDPM Training Algorithm</h3>
        <div class="ddmp-training">
            <h3>Training Process</h3>
            <div class="algorithm-steps">
                <h4>DDPM Training Algorithm:</h4>
                <ol>
                    <li><strong>Sample:</strong> Get clean image x₀ from MNIST dataset</li>
                    <li><strong>Random Timestep:</strong> Sample t uniformly from [0, T-1]</li>
                    <li><strong>Add Noise:</strong> Create x_t using forward process</li>
                    <li><strong>Predict:</strong> Use UNet to predict noise ε given x_t and t</li>
                    <li><strong>Loss:</strong> Compute L2 loss between predicted and true noise</li>
                    <li><strong>Backprop:</strong> Update UNet parameters</li>
                </ol>
            </div>
            
            <div class="mnist-section">
                <div class="variance-schedule">
                    <h4>DDPM Training Configuration:</h4>
                    <strong>Timesteps:</strong> T = 300<br>
                    <strong>Batch Size:</strong> 128<br>
                    <strong>Epochs:</strong> 20<br>
                    <strong>Optimizer:</strong> Adam (lr=1e-3)<br>
                    <strong>LR Schedule:</strong> Exponential decay (γ=0.99)<br>
                    <strong>Hidden Dimension:</strong> D = 64
                </div>
            </div>
        </div>
        
        <h3>2.4 DDPM Sampling Algorithm</h3>
        <div class="implementation-section">
            <p>The sampling process iteratively denoises pure noise into coherent MNIST digits using the learned reverse process.</p>
            
            <div class="algorithm-steps">
                <h4>DDPM Sampling Algorithm:</h4>
                <ol>
                    <li><strong>Initialize:</strong> Start with pure noise x_T ~ N(0, I)</li>
                    <li><strong>Reverse Process:</strong> For t = T-1 down to 0:</li>
                    <li><strong>Predict Noise:</strong> ε_θ(x_t, t) using trained UNet</li>
                    <li><strong>Compute x_0:</strong> Estimate clean image from current state</li>
                    <li><strong>Step Back:</strong> Calculate x_{t-1} using DDPM reverse formula</li>
                    <li><strong>Add Variance:</strong> Include stochastic component for non-deterministic sampling</li>
                </ol>
            </div>
            
            <div class="math-section">
                <h4>DDPM Reverse Process:</h4>
                <img src="../images/diffusion-b-ddpm-reverse-process.png" alt="DDPM Reverse Process Mathematics" style="max-width: 100%; height: auto; border-radius: 4px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </div>
        </div>
        
        <h3>Time-Conditioned Results</h3>
        <div class="loss-curves">
            <div class="loss-curve-item">
                <img src="../images/diffusion-b-time-conditioned-loss-curve.png" alt="Time-Conditioned Training Loss" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="label">Time-Conditioned Training Loss</div>
                <div class="description">20 epochs with exponential LR decay</div>
            </div>
        </div>
        
        <div class="training-progression">
            <div class="epoch-item">
                <h4>Epoch 5</h4>
                <img src="../images/diffusion-b-time-epoch5.png" alt="Time-Conditioned Epoch 5" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="description">Early training progress</div>
            </div>
            
            <div class="epoch-item final">
                <h4>Epoch 20</h4>
                <img src="../images/diffusion-b-time-epoch20.png" alt="Time-Conditioned Epoch 20" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="description">Final generation quality</div>
            </div>
        </div>
        
        <h2>Part 2.4: Class-Conditioned Diffusion</h2>
        
        <div class="class-conditioning-section">
            <h3>Adding Class Conditioning for Controlled Generation</h3>
            <p>By conditioning on digit classes (0-9), we gain precise control over what the model generates while enabling classifier-free guidance.</p>
            
            <div class="architecture-diagram">
                <div class="diagram-title">Class and Time Conditioned UNet</div>
                <img src="../images/diffusion-b-class-conditioned-unet.png" alt="Class-Conditioned UNet Architecture" style="max-width: 100%; height: auto; border-radius: 4px;">
            </div>
            
            <div class="code-snippet">
# Class conditioning implementation
fc1_t = FCBlock(1, hidden_dim)      # Time embedding
fc1_c = FCBlock(10, hidden_dim)     # Class embedding (one-hot)
fc2_t = FCBlock(1, hidden_dim)
fc2_c = FCBlock(10, hidden_dim)

# Conditional dropout (10% unconditional training)
if random.random() < 0.1:
    c = torch.zeros_like(c)  # Drop class conditioning

# Embed both conditions
t1 = fc1_t(t_normalized)
c1 = fc1_c(c)
t2 = fc2_t(t_normalized)
c2 = fc2_c(c)

# Multiplicative and additive conditioning
unflatten = c1 * unflatten + t1
up1 = c2 * up1 + t2
            </div>
            
            <div class="algorithm-steps">
                <h4>Class-Conditional Training:</h4>
                <ol>
                    <li><strong>One-Hot Encoding:</strong> Convert digit labels to 10-dimensional vectors</li>
                    <li><strong>Conditional Dropout:</strong> 10% of time, set class vector to zero</li>
                    <li><strong>Dual Conditioning:</strong> Inject both time and class information</li>
                    <li><strong>Mixed Training:</strong> Learn both conditional and unconditional generation</li>
                </ol>
            </div>
        </div>
        
        <h3>Classifier-Free Guidance (CFG)</h3>
        <div class="cfg-sampling">
            <h3>Enhanced Generation Quality</h3>
            <p>CFG combines conditional and unconditional predictions to improve generation quality and adherence to class conditioning.</p>
            
            <div class="math-section">
                <h4>CFG for Class-Conditioned Generation:</h4>
                <img src="../images/diffusion-b-cfg-class-equation.png" alt="Class-Conditioned CFG Mathematics" style="max-width: 100%; height: auto; border-radius: 4px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
            </div>
            
            <div class="algorithm-steps">
                <h4>CFG Sampling Process:</h4>
                <ol>
                    <li><strong>Conditional Prediction:</strong> ε_θ(x_t, t, c) with class c</li>
                    <li><strong>Unconditional Prediction:</strong> ε_θ(x_t, t, ∅) with empty class</li>
                    <li><strong>Guidance Scale:</strong> γ = 5.0 for enhanced quality</li>
                    <li><strong>Combined Estimate:</strong> Extrapolate beyond conditional prediction</li>
                </ol>
            </div>
        </div>
        
        <h3>Class-Conditioned Results</h3>
        <div class="loss-curves">
            <div class="loss-curve-item">
                <img src="../images/diffusion-b-class-conditioned-loss-curve.png" alt="Class-Conditioned Training Loss" style="max-width: 100%; height: auto; border-radius: 4px;">
                <div class="label">Class-Conditioned Training Loss</div>
                <div class="description">20 epochs with class and time conditioning</div>
            </div>
        </div>
        
        <h3>Generated Digits by Class</h3>
        <div class="training-progression">
            <div class="epoch-item">
                <h4>Epoch 5</h4>
                <div class="generated-digits">
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit0.png" alt="Generated 0" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">0</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit1.png" alt="Generated 1" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">1</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit2.png" alt="Generated 2" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">2</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit3.png" alt="Generated 3" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">3</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit4.png" alt="Generated 4" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">4</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit5.png" alt="Generated 5" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">5</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit6.png" alt="Generated 6" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">6</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit7.png" alt="Generated 7" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">7</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit8.png" alt="Generated 8" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">8</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch5-digit9.png" alt="Generated 9" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">9</div>
                    </div>
                </div>
            </div>
            
            <div class="epoch-item final">
                <h4>Epoch 20 (Final)</h4>
                <div class="generated-digits">
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit0.png" alt="Final Generated 0" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">0</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit1.png" alt="Final Generated 1" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">1</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit2.png" alt="Final Generated 2" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">2</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit3.png" alt="Final Generated 3" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">3</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit4.png" alt="Final Generated 4" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">4</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit5.png" alt="Final Generated 5" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">5</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit6.png" alt="Final Generated 6" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">6</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit7.png" alt="Final Generated 7" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">7</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit8.png" alt="Final Generated 8" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">8</div>
                    </div>
                    <div class="digit-item">
                        <img src="../images/diffusion-b-class-epoch20-digit9.png" alt="Final Generated 9" style="width: 100%; border-radius: 2px;">
                        <div class="digit-label">9</div>
                    </div>
                </div>
            </div>
        </div>
        
        <h2>My Results</h2>
        
        <div class="my-results">
            <h3>Implementation Achievements</h3>
            <p>Successfully implemented and trained three different diffusion model variants from scratch, demonstrating deep understanding of UNet architectures, DDPM mathematics, and conditional generation techniques.</p>
        </div>
        
        <h3>Model Comparison</h3>
        <div class="denoising-comparison">
            <div class="denoise-method one-step">
                <h4>Single-Step Denoiser</h4>
                <img src="../images/diffusion-b-comparison-single-step.png" alt="Single-Step Results" style="max-width: 100%; height: auto; border-radius: 4px;">
                <p>Fast but limited to specific noise levels</p>
            </div>
            
            <div class="denoise-method diffusion">
                <h4>Time-Conditioned DDPM</h4>
                <img src="../images/diffusion-b-comparison-time-conditioned.png" alt="Time-Conditioned Results" style="max-width: 100%; height: auto; border-radius: 4px;">
                <p>Better quality through iterative refinement</p>
            </div>
            
            <div class="denoise-method diffusion">
                <h4>Class-Conditioned DDPM + CFG</h4>
                <img src="../images/diffusion-b-comparison-class-conditioned.png" alt="Class-Conditioned Results" style="max-width: 100%; height: auto; border-radius: 4px;">
                <p>Highest quality with precise control</p>
            </div>
        </div>
        
        <h3>Training Insights and Challenges</h3>
        <div class="implementation-section">
            <ul>
                <li><strong>Architecture Design:</strong> Balancing model capacity with training efficiency through proper hidden dimensions</li>
                <li><strong>Conditioning Mechanisms:</strong> Understanding additive vs. multiplicative conditioning for different information types</li>
                <li><strong>Variance Scheduling:</strong> The critical role of β schedules in training stability and generation quality</li>
                <li><strong>CFG Trade-offs:</strong> Balancing quality improvements against diversity reduction</li>
                <li><strong>Training Dynamics:</strong> Managing long training times and GPU memory constraints</li>
            </ul>
        </div>
        
        <h2>Extra Credit Explorations</h2>
        
        <div class="extra-credit-section">
            <h3>Advanced Techniques</h3>
            
            <div class="results-grid">
                <div class="result-item">
                    <img src="../images/diffusion-b-improved-unet.png" alt="Improved UNet Architecture" style="max-width: 100%; height: auto; border-radius: 4px;">
                    <div class="label">Enhanced UNet</div>
                    <div class="description">Additional skip connections and attention</div>
                </div>
                
                <div class="result-item">
                    <img src="../images/diffusion-b-rectified-flow.png" alt="Rectified Flow Results" style="max-width: 100%; height: auto; border-radius: 4px;">
                    <div class="label">Rectified Flow</div>
                    <div class="description">State-of-the-art sampling efficiency</div>
                </div>
            </div>
            
            <h4>UNet Architecture Improvements:</h4>
            <ul>
                <li><strong>Attention Mechanisms:</strong> Self-attention layers for better global coherence</li>
                <li><strong>Residual Connections:</strong> Additional skip connections for improved gradient flow</li>
                <li><strong>Group Normalization:</strong> Better normalization for small batch sizes</li>
                <li><strong>Adaptive Layer Scaling:</strong> Dynamic feature scaling based on timestep</li>
            </ul>
            
            <h4>Rectified Flow Implementation:</h4>
            <p>Replaced DDPM's complex variance schedule with straight-line interpolation between noise and data, achieving faster convergence and improved sample quality with fewer sampling steps.</p>
        </div>
        
        <h2>Key Learnings</h2>
        
        <div class="implementation-section">
            <h3>Deep Learning and Architecture Design</h3>
            <ul>
                <li><strong>UNet Mastery:</strong> Understanding encoder-decoder architectures with skip connections for multi-scale processing</li>
                <li><strong>Conditioning Strategies:</strong> Different approaches for injecting control signals into neural networks</li>
                <li><strong>Training Stability:</strong> Learning rate scheduling, gradient clipping, and architecture choices for stable training</li>
                <li><strong>Memory Optimization:</strong> Efficient tensor operations and checkpointing for GPU memory management</li>
                <li><strong>Hyperparameter Sensitivity:</strong> Understanding the impact of batch size, learning rate, and architecture choices</li>
            </ul>
            
            <h3>Diffusion Model Theory</h3>
            <ul>
                <li><strong>DDPM Mathematics:</strong> Deep understanding of forward and reverse processes, variance schedules</li>
                <li><strong>Noise Scheduling:</strong> How β schedules affect training dynamics and generation quality</li>
                <li><strong>Classifier-Free Guidance:</strong> Mathematical foundation and practical implementation of CFG</li>
                <li><strong>Conditional Generation:</strong> Techniques for controlling generative models with external signals</li>
                <li><strong>Sampling Algorithms:</strong> Trade-offs between sampling steps, quality, and diversity</li>
            </ul>
            
            <h3>Practical Implementation Skills</h3>
            <ul>
                <li><strong>PyTorch Proficiency:</strong> Advanced tensor operations, custom loss functions, and training loops</li>
                <li><strong>Debugging Strategies:</strong> Identifying and fixing issues in complex generative models</li>
                <li><strong>Experiment Design:</strong> Systematic evaluation of different architectures and hyperparameters</li>
                <li><strong>Model Checkpointing:</strong> Robust training workflows with resume capabilities</li>
                <li><strong>Visualization Tools:</strong> Creating informative plots and comparisons for model evaluation</li>
            </ul>
        </div>
        
        <h2>Impact and Applications</h2>
        
        <div class="key-info">
            <h3>Foundational Understanding</h3>
            <p><strong>Research Foundation:</strong> Deep understanding of generative modeling principles for future research</p>
            <p><strong>Architecture Design:</strong> Skills in designing and implementing neural network architectures</p>
            <p><strong>Training Methodologies:</strong> Experience with complex training procedures and optimization strategies</p>
            <p><strong>Conditional Generation:</strong> Understanding how to control generative models for specific applications</p>
            <p><strong>Scalability Principles:</strong> Knowledge of how these techniques scale to larger, more complex datasets</p>
            <p><strong>State-of-the-Art Connection:</strong> Direct experience with the foundations underlying modern AI systems</p>
        </div>
        
        <div class="nav-back" style="margin-top: 50px; text-align: center;">
            <a href="../index.html">← Back to All Projects</a>
        </div>
    </div>
</body>
</html>